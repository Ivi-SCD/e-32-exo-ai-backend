{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recall Optimization for Exoplanet Classifier\n",
        "\n",
        "> Goal: Increase recall to 98% while maintaining reasonable precision\n",
        "\n",
        "## Strategies:\n",
        "1. **Threshold Optimization**: Find threshold that gives 98% recall\n",
        "2. **Class Weighting**: Balance classes to favor recall\n",
        "3. **Cost-Sensitive Learning**: Penalize false negatives more\n",
        "4. **Feature Engineering**: Add recall-focused features\n",
        "5. **Ensemble Methods**: Combine multiple models optimized for recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import (roc_auc_score, average_precision_score, balanced_accuracy_score,\n",
        "                             precision_recall_curve, confusion_matrix, brier_score_loss,\n",
        "                             classification_report, recall_score, precision_score, f1_score)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import joblib, json, math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_theme(context='notebook', style='dark')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data and preprocessing (same as before)\n",
        "df = pd.read_csv('data/processed/exoplanets_unified_derived_imputed.csv')\n",
        "\n",
        "# Target encoding\n",
        "POSITIVE_SET = {'CONFIRMED', 'CANDIDATE'}\n",
        "df['disposition_upper'] = df.get('disposition', 'UNKNOWN').fillna('UNKNOWN').str.upper()\n",
        "y = df['disposition_upper'].apply(lambda v: 1 if v in POSITIVE_SET else 0)\n",
        "\n",
        "print(f'Positive Rate: {y.mean():.3f}')\n",
        "print(f'Total samples: {len(df)}')\n",
        "print(f'Positive samples: {y.sum()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load existing models and get baseline predictions\n",
        "hgb = joblib.load('./models/hgb_baseline.pkl')\n",
        "rf = joblib.load('./models/rf_model.pkl')\n",
        "imp = joblib.load('./models/imputer.pkl')\n",
        "\n",
        "# Feature selection (same as before)\n",
        "drop_prefixes = ['orbital_period_err', 'planet_radius_re_err', 'transit_depth_err',\n",
        "                 'stellar_teff_err', 'stellar_radius_err', 'stellar_mass_err']\n",
        "\n",
        "raw_duplicate = {'planet_eq_temp_k', 'planet_insolation_earth'}\n",
        "id_like = {'host_name', 'planet_name', 'source_catalog', 'disposition', 'disposition_upper'}\n",
        "\n",
        "features = []\n",
        "for c in df.columns:\n",
        "    if c in id_like or c in raw_duplicate:\n",
        "        continue\n",
        "    if any(c.startswith(p) for p in drop_prefixes):\n",
        "        continue\n",
        "    features.append(c)\n",
        "\n",
        "# Separate numeric vs categorical\n",
        "numeric_cols = [c for c in features if pd.api.types.is_numeric_dtype(df[c])]\n",
        "categorical_cols = [c for c in features if c not in numeric_cols]\n",
        "\n",
        "print(f'Features: {len(features)} (Numeric: {len(numeric_cols)}, Categorical: {len(categorical_cols)})')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-hot encode categorical features\n",
        "low_card_threshold = 12\n",
        "encoded_parts = []\n",
        "\n",
        "for c in categorical_cols:\n",
        "    card = df[c].nunique(dropna=True)\n",
        "    if card <= low_card_threshold:\n",
        "        dummies = pd.get_dummies(df[c], prefix=c, dummy_na=True)\n",
        "        encoded_parts.append(dummies)\n",
        "\n",
        "if encoded_parts:\n",
        "    X_cat = pd.concat(encoded_parts, axis=1)\n",
        "else:\n",
        "    X_cat = pd.DataFrame(index=df.index)\n",
        "\n",
        "X_num = df[numeric_cols].copy()\n",
        "X = pd.concat([X_num, X_cat], axis=1)\n",
        "\n",
        "# Remove constant columns\n",
        "const_cols = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]\n",
        "X = X.drop(columns=const_cols)\n",
        "\n",
        "print(f'Final feature matrix shape: {X.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train-test split (same as original)\n",
        "train_idx, test_idx = train_test_split(X.index, test_size=0.20, stratify=y, random_state=32)\n",
        "X_train, X_test = X.loc[train_idx], X.loc[test_idx]\n",
        "y_train, y_test = y.loc[train_idx], y.loc[test_idx]\n",
        "\n",
        "# Impute missing values\n",
        "X_train_imp = pd.DataFrame(imp.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "X_test_imp = pd.DataFrame(imp.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f'Train: {X_train_imp.shape}, Test: {X_test_imp.shape}')\n",
        "\n",
        "# Get baseline predictions\n",
        "prob_hgb = hgb.predict_proba(X_test_imp)[:, 1]\n",
        "prob_rf = rf.predict_proba(X_test_imp)[:, 1]\n",
        "prob_ensemble = (prob_hgb + prob_rf) / 2\n",
        "\n",
        "print(\"Baseline predictions obtained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strategy 1: Threshold Optimization for 98% Recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find threshold for 98% recall\n",
        "def find_threshold_for_recall(y_true, y_proba, target_recall=0.98, min_precision=0.1):\n",
        "    \"\"\"Find threshold that achieves target recall with minimum precision constraint\"\"\"\n",
        "    prec, rec, thr = precision_recall_curve(y_true, y_proba)\n",
        "    \n",
        "    # Find points with recall >= target_recall and precision >= min_precision\n",
        "    valid_indices = (rec >= target_recall) & (prec >= min_precision)\n",
        "    \n",
        "    if not valid_indices.any():\n",
        "        # If no valid point, find highest recall with any precision\n",
        "        best_idx = np.argmax(rec)\n",
        "        return {\n",
        "            'threshold': thr[best_idx] if best_idx < len(thr) else 0.0,\n",
        "            'recall': rec[best_idx],\n",
        "            'precision': prec[best_idx],\n",
        "            'f1': 2 * (prec[best_idx] * rec[best_idx]) / (prec[best_idx] + rec[best_idx]) if (prec[best_idx] + rec[best_idx]) > 0 else 0\n",
        "        }\n",
        "    \n",
        "    # Among valid points, choose the one with highest precision\n",
        "    valid_indices = np.where(valid_indices)[0]\n",
        "    best_idx = valid_indices[np.argmax(prec[valid_indices])]\n",
        "    \n",
        "    return {\n",
        "        'threshold': thr[best_idx] if best_idx < len(thr) else 0.0,\n",
        "        'recall': rec[best_idx],\n",
        "        'precision': prec[best_idx],\n",
        "        'f1': 2 * (prec[best_idx] * rec[best_idx]) / (prec[best_idx] + rec[best_idx]) if (prec[best_idx] + rec[best_idx]) > 0 else 0\n",
        "    }\n",
        "\n",
        "# Test different models\n",
        "models = {\n",
        "    'HGB': prob_hgb,\n",
        "    'Random Forest': prob_rf,\n",
        "    'Ensemble': prob_ensemble\n",
        "}\n",
        "\n",
        "threshold_results = {}\n",
        "for name, prob in models.items():\n",
        "    result = find_threshold_for_recall(y_test, prob, target_recall=0.98, min_precision=0.1)\n",
        "    threshold_results[name] = result\n",
        "    print(f\"{name}: Threshold={result['threshold']:.4f}, Recall={result['recall']:.3f}, Precision={result['precision']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strategy 2: Class Weighting for Recall Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate class weights for recall optimization\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Standard class weights (balanced)\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "# Recall-focused weights (heavily favor positive class)\n",
        "recall_weights = {0: 1.0, 1: 10.0}  # 10x weight for positive class\n",
        "extreme_recall_weights = {0: 1.0, 1: 20.0}  # 20x weight for positive class\n",
        "\n",
        "print(f\"Balanced weights: {class_weight_dict}\")\n",
        "print(f\"Recall-focused weights: {recall_weights}\")\n",
        "print(f\"Extreme recall weights: {extreme_recall_weights}\")\n",
        "\n",
        "# Train models with different class weights\n",
        "weight_strategies = {\n",
        "    'Balanced': class_weight_dict,\n",
        "    'Recall-Focused': recall_weights,\n",
        "    'Extreme-Recall': extreme_recall_weights\n",
        "}\n",
        "\n",
        "weighted_models = {}\n",
        "for strategy, weights in weight_strategies.items():\n",
        "    # HGB with class weights\n",
        "    hgb_weighted = HistGradientBoostingClassifier(\n",
        "        random_state=32,\n",
        "        class_weight=weights\n",
        "    )\n",
        "    hgb_weighted.fit(X_train_imp, y_train)\n",
        "    \n",
        "    # RF with class weights\n",
        "    rf_weighted = RandomForestClassifier(\n",
        "        n_estimators=600,\n",
        "        random_state=32,\n",
        "        class_weight=weights,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf_weighted.fit(X_train_imp, y_train)\n",
        "    \n",
        "    # Get predictions\n",
        "    prob_hgb_w = hgb_weighted.predict_proba(X_test_imp)[:, 1]\n",
        "    prob_rf_w = rf_weighted.predict_proba(X_test_imp)[:, 1]\n",
        "    prob_ensemble_w = (prob_hgb_w + prob_rf_w) / 2\n",
        "    \n",
        "    weighted_models[strategy] = {\n",
        "        'hgb': hgb_weighted,\n",
        "        'rf': rf_weighted,\n",
        "        'prob_hgb': prob_hgb_w,\n",
        "        'prob_rf': prob_rf_w,\n",
        "        'prob_ensemble': prob_ensemble_w\n",
        "    }\n",
        "    \n",
        "    # Find threshold for 98% recall\n",
        "    result = find_threshold_for_recall(y_test, prob_ensemble_w, target_recall=0.98, min_precision=0.1)\n",
        "    print(f\"{strategy}: Threshold={result['threshold']:.4f}, Recall={result['recall']:.3f}, Precision={result['precision']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strategy 3: Cost-Sensitive Learning with Custom Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom cost matrix: heavily penalize false negatives\n",
        "cost_matrix = {\n",
        "    'tn': 0,    # True Negative (correctly predicted negative)\n",
        "    'fp': 1,    # False Positive (predicted positive, actual negative) - minor cost\n",
        "    'fn': 50,   # False Negative (predicted negative, actual positive) - HIGH COST\n",
        "    'tp': 0     # True Positive (correctly predicted positive)\n",
        "}\n",
        "\n",
        "print(f\"Cost matrix: {cost_matrix}\")\n",
        "print(f\"FN cost is {cost_matrix['fn']}x higher than FP cost\")\n",
        "\n",
        "# Train models with cost-sensitive approach\n",
        "# For HGB, we'll use extreme class weights to simulate cost-sensitive learning\n",
        "cost_sensitive_weights = {\n",
        "    0: 1.0,   # Normal weight for negative class\n",
        "    1: cost_matrix['fn']  # High weight for positive class (matches FN cost)\n",
        "}\n",
        "\n",
        "hgb_cost = HistGradientBoostingClassifier(\n",
        "    random_state=32,\n",
        "    class_weight=cost_sensitive_weights\n",
        ")\n",
        "hgb_cost.fit(X_train_imp, y_train)\n",
        "\n",
        "rf_cost = RandomForestClassifier(\n",
        "    n_estimators=600,\n",
        "    random_state=32,\n",
        "    class_weight=cost_sensitive_weights,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_cost.fit(X_train_imp, y_train)\n",
        "\n",
        "# Get predictions\n",
        "prob_hgb_cost = hgb_cost.predict_proba(X_test_imp)[:, 1]\n",
        "prob_rf_cost = rf_cost.predict_proba(X_test_imp)[:, 1]\n",
        "prob_ensemble_cost = (prob_hgb_cost + prob_rf_cost) / 2\n",
        "\n",
        "# Find threshold for 98% recall\n",
        "result_cost = find_threshold_for_recall(y_test, prob_ensemble_cost, target_recall=0.98, min_precision=0.1)\n",
        "print(f\"Cost-Sensitive: Threshold={result_cost['threshold']:.4f}, Recall={result_cost['recall']:.3f}, Precision={result_cost['precision']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strategy 4: Feature Engineering for Recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add recall-focused features\n",
        "def add_recall_features(df):\n",
        "    \"\"\"Add features that are highly correlated with positive class\"\"\"\n",
        "    df_enhanced = df.copy()\n",
        "    \n",
        "    # High-confidence positive indicators\n",
        "    if 'transit_depth_ppm' in df.columns and 'planet_radius_re' in df.columns:\n",
        "        # Strong transit signal\n",
        "        df_enhanced['strong_transit_signal'] = (\n",
        "            (df['transit_depth_ppm'] > df['transit_depth_ppm'].quantile(0.7)) &\n",
        "            (df['planet_radius_re'] > 0.5) & (df['planet_radius_re'] < 5.0)\n",
        "        ).astype(int)\n",
        "    \n",
        "    # Habitable zone indicators\n",
        "    if 'planet_insolation_earth' in df.columns:\n",
        "        df_enhanced['in_habitable_zone'] = (\n",
        "            (df['planet_insolation_earth'] > 0.3) & (df['planet_insolation_earth'] < 3.0)\n",
        "        ).astype(int)\n",
        "    \n",
        "    # Stellar characteristics favorable for planet detection\n",
        "    if 'stellar_teff_k' in df.columns:\n",
        "        df_enhanced['favorable_stellar_type'] = (\n",
        "            (df['stellar_teff_k'] > 4000) & (df['stellar_teff_k'] < 7000)\n",
        "        ).astype(int)\n",
        "    \n",
        "    # Orbital period in detection-friendly range\n",
        "    if 'orbital_period_days' in df.columns:\n",
        "        df_enhanced['detection_friendly_period'] = (\n",
        "            (df['orbital_period_days'] > 10) & (df['orbital_period_days'] < 500)\n",
        "        ).astype(int)\n",
        "    \n",
        "    # Combined confidence score\n",
        "    recall_features = ['strong_transit_signal', 'in_habitable_zone', 'favorable_stellar_type', 'detection_friendly_period']\n",
        "    available_features = [f for f in recall_features if f in df_enhanced.columns]\n",
        "    \n",
        "    if available_features:\n",
        "        df_enhanced['recall_confidence_score'] = df_enhanced[available_features].sum(axis=1)\n",
        "    \n",
        "    return df_enhanced\n",
        "\n",
        "# Apply feature engineering\n",
        "df_enhanced = add_recall_features(df)\n",
        "new_features = [col for col in df_enhanced.columns if col not in df.columns]\n",
        "print(f\"Added {len(new_features)} recall-focused features: {new_features}\")\n",
        "\n",
        "# Update feature matrix with enhanced features\n",
        "X_enhanced = X.copy()\n",
        "for feature in new_features:\n",
        "    if feature in df_enhanced.columns:\n",
        "        X_enhanced[feature] = df_enhanced[feature]\n",
        "\n",
        "# Update train-test split\n",
        "X_train_enhanced, X_test_enhanced = X_enhanced.loc[train_idx], X_enhanced.loc[test_idx]\n",
        "\n",
        "# Impute enhanced features\n",
        "X_train_enhanced_imp = pd.DataFrame(\n",
        "    imp.fit_transform(X_train_enhanced), \n",
        "    columns=X_train_enhanced.columns, \n",
        "    index=X_train_enhanced.index\n",
        ")\n",
        "X_test_enhanced_imp = pd.DataFrame(\n",
        "    imp.transform(X_test_enhanced), \n",
        "    columns=X_test_enhanced.columns, \n",
        "    index=X_test_enhanced.index\n",
        ")\n",
        "\n",
        "print(f\"Enhanced feature matrix: {X_enhanced.shape}\")\n",
        "print(f\"New features added: {list(new_features)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train models with enhanced features and recall-focused weights\n",
        "hgb_enhanced = HistGradientBoostingClassifier(\n",
        "    random_state=32,\n",
        "    class_weight=cost_sensitive_weights\n",
        ")\n",
        "hgb_enhanced.fit(X_train_enhanced_imp, y_train)\n",
        "\n",
        "rf_enhanced = RandomForestClassifier(\n",
        "    n_estimators=600,\n",
        "    random_state=32,\n",
        "    class_weight=cost_sensitive_weights,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_enhanced.fit(X_train_enhanced_imp, y_train)\n",
        "\n",
        "# Get predictions\n",
        "prob_hgb_enhanced = hgb_enhanced.predict_proba(X_test_enhanced_imp)[:, 1]\n",
        "prob_rf_enhanced = rf_enhanced.predict_proba(X_test_enhanced_imp)[:, 1]\n",
        "prob_ensemble_enhanced = (prob_hgb_enhanced + prob_rf_enhanced) / 2\n",
        "\n",
        "# Find threshold for 98% recall\n",
        "result_enhanced = find_threshold_for_recall(y_test, prob_ensemble_enhanced, target_recall=0.98, min_precision=0.1)\n",
        "print(f\"Enhanced Features: Threshold={result_enhanced['threshold']:.4f}, Recall={result_enhanced['recall']:.3f}, Precision={result_enhanced['precision']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strategy 5: Advanced Ensemble with Recall Focus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create advanced ensemble with multiple models optimized for recall\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Individual models with different strategies\n",
        "models_recall = [\n",
        "    ('hgb_recall', HistGradientBoostingClassifier(random_state=32, class_weight=cost_sensitive_weights)),\n",
        "    ('rf_recall', RandomForestClassifier(n_estimators=600, random_state=32, class_weight=cost_sensitive_weights, n_jobs=-1)),\n",
        "    ('logit_recall', LogisticRegression(random_state=32, class_weight=cost_sensitive_weights, max_iter=1000))\n",
        "]\n",
        "\n",
        "# Voting ensemble\n",
        "ensemble_recall = VotingClassifier(models_recall, voting='soft')\n",
        "ensemble_recall.fit(X_train_enhanced_imp, y_train)\n",
        "\n",
        "# Get predictions\n",
        "prob_ensemble_advanced = ensemble_recall.predict_proba(X_test_enhanced_imp)[:, 1]\n",
        "\n",
        "# Find threshold for 98% recall\n",
        "result_advanced = find_threshold_for_recall(y_test, prob_ensemble_advanced, target_recall=0.98, min_precision=0.1)\n",
        "print(f\"Advanced Ensemble: Threshold={result_advanced['threshold']:.4f}, Recall={result_advanced['recall']:.3f}, Precision={result_advanced['precision']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Comparison and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all strategies\n",
        "results_comparison = {\n",
        "    'Original Ensemble': threshold_results['Ensemble'],\n",
        "    'Cost-Sensitive': result_cost,\n",
        "    'Enhanced Features': result_enhanced,\n",
        "    'Advanced Ensemble': result_advanced\n",
        "}\n",
        "\n",
        "print(\"\\n=== RECALL OPTIMIZATION RESULTS ===\")\n",
        "print(\"Strategy\\t\\t\\tThreshold\\tRecall\\t\\tPrecision\\tF1-Score\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for strategy, result in results_comparison.items():\n",
        "    print(f\"{strategy:<20}\\t{result['threshold']:.4f}\\t\\t{result['recall']:.3f}\\t\\t{result['precision']:.3f}\\t\\t{result['f1']:.3f}\")\n",
        "\n",
        "# Find best strategy for 98% recall\n",
        "target_recall = 0.98\n",
        "best_strategy = None\n",
        "best_precision = 0\n",
        "\n",
        "for strategy, result in results_comparison.items():\n",
        "    if result['recall'] >= target_recall and result['precision'] > best_precision:\n",
        "        best_strategy = strategy\n",
        "        best_precision = result['precision']\n",
        "\n",
        "print(f\"\\n=== BEST STRATEGY FOR 98% RECALL ===\")\n",
        "if best_strategy:\n",
        "    best_result = results_comparison[best_strategy]\n",
        "    print(f\"Strategy: {best_strategy}\")\n",
        "    print(f\"Threshold: {best_result['threshold']:.4f}\")\n",
        "    print(f\"Recall: {best_result['recall']:.3f}\")\n",
        "    print(f\"Precision: {best_result['precision']:.3f}\")\n",
        "    print(f\"F1-Score: {best_result['f1']:.3f}\")\n",
        "else:\n",
        "    print(\"No strategy achieved exactly 98% recall. Showing closest:\")\n",
        "    closest_strategy = max(results_comparison.items(), key=lambda x: x[1]['recall'])\n",
        "    print(f\"Strategy: {closest_strategy[0]}\")\n",
        "    print(f\"Recall: {closest_strategy[1]['recall']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nasenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
